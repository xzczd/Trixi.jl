<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Performance · Trixi.jl</title><link rel="canonical" href="https://trixi-framework.github.io/Trixi.jl/stable/performance/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="Trixi.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">Trixi.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../visualization/">Visualization</a></li><li><a class="tocitem" href="../conventions/">Conventions</a></li><li><a class="tocitem" href="../time_integration/">Time integration</a></li><li><a class="tocitem" href="../callbacks/">Callbacks</a></li><li><a class="tocitem" href="../development/">Development</a></li><li class="is-active"><a class="tocitem" href>Performance</a><ul class="internal"><li><a class="tocitem" href="#Manual-benchmarking"><span>Manual benchmarking</span></a></li><li><a class="tocitem" href="#Automated-benchmarking"><span>Automated benchmarking</span></a></li><li><a class="tocitem" href="#Runtime-performance-vs.-latency-aka-using-@nospecialize-selectively"><span>Runtime performance vs. latency aka using <code>@nospecialize</code> selectively</span></a></li></ul></li><li><a class="tocitem" href="../parallelization/">Parallelization</a></li><li><a class="tocitem" href="../testing/">Testing</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../adding_a_new_equation/">Adding a new equation</a></li><li><a class="tocitem" href="../differentiable_programming/">Differentiable programming</a></li></ul></li><li><a class="tocitem" href="../troubleshooting/">Troubleshooting</a></li><li><a class="tocitem" href="../styleguide/">Style guide</a></li><li><a class="tocitem" href="../github-git/">GitHub &amp; Git</a></li><li><span class="tocitem">Reference</span><ul><li><a class="tocitem" href="../reference-trixi/">Trixi.jl</a></li><li><a class="tocitem" href="../reference-trixi2vtk/">Trixi2Vtk.jl</a></li><li><a class="tocitem" href="../reference-trixi2img/">Trixi2Img.jl</a></li></ul></li><li><a class="tocitem" href="../authors/">Authors</a></li><li><a class="tocitem" href="../contributing/">Contributing</a></li><li><a class="tocitem" href="../license/">License</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Performance</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Performance</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/trixi-framework/Trixi.jl/blob/master/docs/src/performance.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Performance"><a class="docs-heading-anchor" href="#Performance">Performance</a><a id="Performance-1"></a><a class="docs-heading-anchor-permalink" href="#Performance" title="Permalink"></a></h1><p>Trixi.jl is designed to balance performance and readability. Since Julia provides a lot of zero-cost abstractions, it is often possible to optimize both goals simultaneously.</p><p>The usual development workflow in Julia is</p><ol><li>Make it work.</li><li>Make it fast.</li></ol><p>To achieve the second step, you should be familiar with (at least) the section on <a href="https://docs.julialang.org/en/v1/manual/performance-tips/">performance tips in the Julia manual</a>. Here, we just list some important aspects you should consider when developing Trixi.</p><ul><li>Consider using <code>@views</code>/<code>view(...)</code> when using array slices, except on the left-side of an assignment (<a href="https://docs.julialang.org/en/v1/manual/performance-tips/#man-performance-views">further details</a>).</li><li>Functions are essentially for free, since they are usually automatically inlined where it makes sense (using <code>@inline</code> can be used as an additional hint to the compiler) (<a href="https://docs.julialang.org/en/v1/manual/performance-tips/#Break-functions-into-multiple-definitions">further details</a>).</li><li>Function barriers can improve performance due to type stability (<a href="https://docs.julialang.org/en/v1/manual/performance-tips/#kernel-functions">further details</a>).</li><li>Look for type instabilities using <code>@code_warntype</code>. Consider using <code>@descend</code> from <a href="https://github.com/JuliaDebug/Cthulhu.jl">Cthulhu.jl</a> to investigate deeper call chains.</li></ul><h2 id="Manual-benchmarking"><a class="docs-heading-anchor" href="#Manual-benchmarking">Manual benchmarking</a><a id="Manual-benchmarking-1"></a><a class="docs-heading-anchor-permalink" href="#Manual-benchmarking" title="Permalink"></a></h2><p>If you modify some internal parts of Trixi, you should check the impact on performance. Hence, you should at least investigate the performance roughly by comparing the reported timings of several elixirs. Deeper investigations and micro-benchmarks should usually use <a href="https://github.com/JuliaCI/BenchmarkTools.jl">BenchmarkTools.jl</a>. For example, the following steps were used to benchmark the changes introduced in https://github.com/trixi-framework/Trixi.jl/pull/256.</p><ol><li><p><code>git checkout e7ebf3846b3fd62ee1d0042e130afb50d7fe8e48</code> (new version)</p></li><li><p>Start <code>julia --threads=1 --check-bounds=no</code>.</p></li><li><p>Execute the following code in the REPL to benchmark the <code>rhs!</code> call at the final state.</p><pre><code class="language-julia">julia&gt; using BenchmarkTools, Revise; using Trixi

julia&gt; trixi_include(&quot;examples/2d/elixir_euler_sedov_blast_wave.jl&quot;)

julia&gt; du_test = copy(sol.u[end]); u_test = copy(sol.u[end]);

julia&gt; @benchmark Trixi.rhs!(
          $(du_test),
          $(u_test),
          $(semi),
          $(sol.t[end]))
BenchmarkTools.Trial:
 memory estimate:  10.48 KiB
 allocs estimate:  67
 --------------
 minimum time:     4.510 ms (0.00% GC)
 median time:      4.646 ms (0.00% GC)
 mean time:        4.699 ms (0.00% GC)
 maximum time:     7.183 ms (0.00% GC)
 --------------
 samples:          1065
 evals/sample:     1

shell&gt; git checkout 222241ff54f8a4ca9876cc1fc25ae262416a4ea0

julia&gt; trixi_include(&quot;examples/2d/elixir_euler_sedov_blast_wave.jl&quot;)

julia&gt; @benchmark Trixi.rhs!(
          $(du_test),
          $(u_test),
          $(semi),
          $(sol.t[end]))
BenchmarkTools.Trial:
 memory estimate:  10.36 KiB
 allocs estimate:  67
 --------------
 minimum time:     4.500 ms (0.00% GC)
 median time:      4.635 ms (0.00% GC)
 mean time:        4.676 ms (0.00% GC)
 maximum time:     5.880 ms (0.00% GC)
 --------------
 samples:          1070
 evals/sample:     1</code></pre><p>Run the <code>@benchmark ...</code> commands multiple times to see whether there are any significant fluctuations.</p></li></ol><p>Follow these steps for both commits you want to compare. The relevant benchmark results you should typically be looking at are the median and mean values of the runtime and the memory/allocs estimate. In this example, the differences of the runtimes are of the order of the fluctuations one gets when running the benchmarks multiple times. Since the memory/allocs are (roughly) the same, there doesn&#39;t seem to be a significant performance regression here.</p><p>You can also make it more detailed by benchmarking only, e.g., the calculation of the volume terms, but whether that&#39;s necessary depends on the modifications you made and their (potential) impact.</p><h2 id="Automated-benchmarking"><a class="docs-heading-anchor" href="#Automated-benchmarking">Automated benchmarking</a><a id="Automated-benchmarking-1"></a><a class="docs-heading-anchor-permalink" href="#Automated-benchmarking" title="Permalink"></a></h2><p>We use <a href="https://github.com/JuliaCI/PkgBenchmark.jl">PkgBenchmark.jl</a> to provide a standard set of benchmarks for Trixi. The relevant benchmark script is <a href="https://github.com/trixi-framework/Trixi.jl/blob/main/benchmark/benchmarks.jl">benchmark/benchmarks.jl</a>. You can run a standard set of benchmarks via</p><pre><code class="language-julia">julia&gt; using PkgBenchmark, Trixi

julia&gt; results = benchmarkpkg(Trixi, BenchmarkConfig(juliacmd=`$(Base.julia_cmd()) --check-bounds=no --threads=1`))

julia&gt; export_markdown(joinpath(pathof(Trixi) |&gt; dirname |&gt; dirname, &quot;benchmark&quot;, &quot;single_benchmark.md&quot;), results)</code></pre><p>This will save a markdown file with a summary of the benchmark results similar to <a href="https://gist.github.com/ranocha/494fa2529e1e6703c17b08434c090980">this example</a>. Note that this will take quite some time. Additional options are described in the <a href="https://juliaci.github.io/PkgBenchmark.jl/stable">docs of PkgBenchmark.jl</a>. A particularly useful option is to specify a <code>BenchmarkConfig</code> including Julia command line options affecting the performance such as disabling bounds-checking and setting the number of threads.</p><p>A useful feature when developing Trixi is to compare the performance of Trixi&#39;s current state vs. the <code>main</code> branch. This can be achieved by executing</p><pre><code class="language-julia">julia&gt; using PkgBenchmark, Trixi

julia&gt; results = judge(Trixi,
             BenchmarkConfig(juliacmd=`$(Base.julia_cmd()) --check-bounds=no --threads=1`), # target
             BenchmarkConfig(juliacmd=`$(Base.julia_cmd()) --check-bounds=no --threads=1`, id=&quot;main&quot;) # baseline
       )

julia&gt; export_markdown(joinpath(pathof(Trixi) |&gt; dirname |&gt; dirname, &quot;benchmark&quot;, &quot;results.md&quot;), results)</code></pre><p>By default, the <code>target</code> is the current state of the repository. Remember that you need to be in a clean state (commit or stash your changes) to run this successfully. You can also run this comparison and an additional one using two threads via</p><pre><code class="language-julia">julia&gt; include(&quot;benchmark/run_benchmarks.jl&quot;)</code></pre><p>Then, markdown files including the results are saved in <code>benchmark/</code>. <a href="https://gist.github.com/ranocha/bf98d19e288e759d3a36ca0643448efb">This example result</a> was obtained using a GitHub action for the  <a href="https://github.com/trixi-framework/Trixi.jl/pull/535">PR #535</a>. Note that GitHub actions run on in the cloud in a virtual machine. Hence, we do not really have control over it and performance results must be taken with a grain of salt. Nevertheless, significant runtime differences and differences of memory allocations should be robust indicators of performance changes.</p><h2 id="Runtime-performance-vs.-latency-aka-using-@nospecialize-selectively"><a class="docs-heading-anchor" href="#Runtime-performance-vs.-latency-aka-using-@nospecialize-selectively">Runtime performance vs. latency aka using <code>@nospecialize</code> selectively</a><a id="Runtime-performance-vs.-latency-aka-using-@nospecialize-selectively-1"></a><a class="docs-heading-anchor-permalink" href="#Runtime-performance-vs.-latency-aka-using-@nospecialize-selectively" title="Permalink"></a></h2><p>Usually, Julia will compile specialized versions of each method, using as much information from the types of function arguments as possible (based on some <a href="https://docs.julialang.org/en/v1/manual/performance-tips/#Be-aware-of-when-Julia-avoids-specializing">heuristics</a>). The compiler will generate code that is as efficient as comparable code written in a low-level language such as C or Fortran. However, there are cases where the runtime performance does not really matter but the time needed to compile specializations becomes significant. This is related to latency or the time-to-first-plot problem, well-known in the Julia community. In such a case, it can be useful to remove some burden from the compiler by avoiding specialization on every possible argument types using <a href="https://docs.julialang.org/en/v1/base/base/#Base.@nospecialize">the macro <code>@nospecialize</code></a>. A prime example of such a case is pretty printing of <code>struct</code>s in the Julia REPL, see the <a href="https://github.com/trixi-framework/Trixi.jl/pull/447">associated PR</a> for further discussions.</p><p>As a rule of thumb:</p><ul><li>Do not use <code>@nospecialize</code> in performance-critical parts, in particular not for methods involved in computing <code>Trixi.rhs!</code>.</li><li>Consider using <code>@nospecialize</code> for methods like custom implementations of <code>Base.show</code>.</li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../development/">« Development</a><a class="docs-footer-nextpage" href="../parallelization/">Parallelization »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Friday 16 April 2021 10:53">Friday 16 April 2021</span>. Using Julia version 1.6.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
